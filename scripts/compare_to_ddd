import sys
sys.path.append('/home/ruslan/workspaces/depth_correction_ws/src/DeepDepthDenoising/')
import models
import utils
from supervision import get_mask
from depth_correction.datasets.fee_corridor import Dataset
import numpy as np
from numpy.lib.recfunctions import structured_to_unstructured
import open3d as o3d
import matplotlib.pyplot as plt
import torch
import cv2
from tqdm import tqdm


class LidarParams:
    def __init__(self):
        self.proj_fov_up = 45
        self.proj_fov_down = -45
        self.proj_H = 128
        self.proj_W = 1024


def range_projection(points, params):
    """ Project a point cloud into a sphere.
    """
    # laser parameters
    fov_up = params.proj_fov_up / 180.0 * np.pi  # field of view up in rad
    fov_down = params.proj_fov_down / 180.0 * np.pi  # field of view down in rad
    fov = abs(fov_down) + abs(fov_up)  # get field of view total in rad

    # get depth of all points
    depth = np.linalg.norm(points, 2, axis=1)

    # get scan components
    scan_x = points[:, 0]
    scan_y = points[:, 1]
    scan_z = points[:, 2]

    # get angles of all points
    yaw = -np.arctan2(scan_y, scan_x)
    pitch = np.arcsin(scan_z / (depth + 1e-8))

    # get projections in image coords
    proj_x = 0.5 * (yaw / np.pi + 1.0)  # in [0.0, 1.0]
    proj_y = 1.0 - (pitch + abs(fov_down)) / fov  # in [0.0, 1.0]

    # scale to image size using angular resolution
    proj_x *= params.proj_W  # in [0.0, W]
    proj_y *= params.proj_H  # in [0.0, H]

    # round and clamp for use as index
    proj_x = np.floor(proj_x)
    proj_x = np.minimum(params.proj_W - 1, proj_x)
    proj_x = np.maximum(0, proj_x).astype(np.int32)  # in [0,W-1]

    proj_y = np.floor(proj_y)
    proj_y = np.minimum(params.proj_H - 1, proj_y)
    proj_y = np.maximum(0, proj_y).astype(np.int32)  # in [0,H-1]

    # order in decreasing depth
    order = np.argsort(depth)[::-1]
    depth = depth[order]
    proj_y = proj_y[order]
    proj_x = proj_x[order]

    # assing to image
    proj_range = np.full((params.proj_H, params.proj_W), -1, dtype=np.float32)
    proj_range[proj_y, proj_x] = depth

    return proj_range


def depth_to_points(depth, params):
    proj_H, proj_W = depth.shape
    yaw = np.linspace(np.pi, -np.pi, proj_W)
    yaw = np.repeat(yaw[None], proj_H, axis=0)

    fov_up = params.proj_fov_up / 180.0 * np.pi  # field of view up in rad
    fov_down = params.proj_fov_down / 180.0 * np.pi  # field of view down in rad
    pitch = np.linspace(fov_up, fov_down, proj_H)
    pitch = np.repeat(pitch[None].T, proj_W, axis=1)

    x = depth * np.cos(pitch) * np.cos(yaw)
    y = depth * np.cos(pitch) * np.sin(yaw)
    z = depth * np.sin(pitch)

    x = x.reshape((-1))
    y = y.reshape((-1))
    z = z.reshape((-1))
    points = np.stack([x, y, z]).T

    mask = depth.reshape((-1)) > 0.
    points = points[mask]

    return points


if __name__ == '__main__':
    # configs and data
    ds = Dataset()
    lidar_params = LidarParams()
    model_params = {
        'width': lidar_params.proj_W,
        'height': lidar_params.proj_H,
        'ndf': 8,
        'dilation': 1,
        'norm_type': "elu",
        'upsample_type': "nearest"
    }
    device = torch.device('cuda')

    # load denoising (DDD) model
    model = models.get_model(model_params).to(device)
    model_path = '/home/ruslan/workspaces/depthcorr_ws/src/DeepDepthDenoising/weights/ddd'
    utils.init.initialize_weights(model, model_path)

    # for i in tqdm(range(len(ds))):
    for _ in tqdm(range(5)):
        # inference
        i = int(np.random.choice(range(len(ds))))
        cloud, pose = ds[i]
        points = structured_to_unstructured(cloud[['x', 'y', 'z']])
        depth = range_projection(points, lidar_params)
        # depth = cv2.resize(depth, (model_params['width'], model_params['height']), interpolation=cv2.INTER_LINEAR)
        # plt.figure(figsize=(20, 10))
        # plt.imshow(depth)
        # plt.show()

        with torch.no_grad():
            h, w = depth.shape
            depth_tensor = torch.from_numpy(depth).reshape(1, 1, h, w).to(device)
            # mask = torch.full(depth_tensor.shape, 1.).to(device)
            mask, _ = get_mask(depth_tensor)
            mask = mask.to(device)
            predicted_depth, _ = model(depth_tensor, mask)

        depth_smooth = depth_tensor.clone()
        mask = torch.as_tensor(mask, dtype=torch.bool)
        depth_smooth[mask] = predicted_depth[mask]
        depth_smooth = depth_smooth.squeeze().cpu().numpy()
        points_smooth = depth_to_points(depth_smooth, lidar_params)

        # vis result
        plt.figure(figsize=(20, 10))
        plt.subplot(2, 1, 1)
        plt.title('Original')
        plt.imshow(depth)

        plt.subplot(2, 1, 2)
        plt.title('DDD output')
        plt.imshow(depth_smooth)
        plt.show()

        pcd_smooth = o3d.geometry.PointCloud()
        pcd_smooth.points = o3d.utility.Vector3dVector(points_smooth.reshape((-1, 3)))
        pcd_smooth.paint_uniform_color([0.1, 0.1, 0.8])

        # points_init = depth_to_points(depth, lidar_params)
        points_init = points
        pcd_init = o3d.geometry.PointCloud()
        pcd_init.points = o3d.utility.Vector3dVector(points_init.reshape((-1, 3)))
        pcd_init.paint_uniform_color([0.8, 0.1, 0.1])

        o3d.visualization.draw_geometries([pcd_init, pcd_smooth])
