#!/usr/bin/env python
"""Extract static lidar scans from a bag file.

It checks when the sensor didn't move and extracts scans from these periods.

Topics:
- Position of a crystal mounted on the lidar, tracked by total station.
  /total_station_driver/ts_points   [geometry_msgs/PointStamped]
- Lidar scans.
  /points                           [sensor_msgs/PointCloud2]
- Dynamic and static transforms.
  /tf                               [tf2_msgs/TFMessage]
  /tf_static                        [tf2_msgs/TFMessage]
- Lidar raw data.
  /os_node/imu_packets              [ouster_ros/PacketMsg]
  /os_node/lidar_packets            [ouster_ros/PacketMsg]
  /os_node/sensor_info              [cras_ouster_msgs/SensorInfo]
"""

from __future__ import absolute_import, division, print_function
from argparse import ArgumentParser
import numpy as np
import os
from rosbag import Bag, ROSBagException
from ros_numpy import numpify
import rospy
from tf2_ros import BufferCore, TransformException
from tqdm import tqdm
import matplotlib.pyplot as plt
from depth_correction.utils import delta_transform, rotation_angle, translation_norm


def get_arg_parser():
    parser = ArgumentParser(description='Compute localization accuracy from SLAM and data set data.')
    parser.add_argument('bag_paths', nargs='+', default=None, help='Input bag files.')
    return parser

def str_to_sec(stamp):
    sec = float(stamp.split('_')[0])
    nsec = float(stamp.split('_')[1])
    t = sec + nsec / float(1e9)
    return t

def read_poses(path):
    poses = np.genfromtxt(path, delimiter=', ', skip_header=True)
    ids = np.genfromtxt(path, delimiter=', ', dtype=str, skip_header=True)[:, 0].tolist()
    # assert ids == list(range(len(ids)))
    poses = poses[:, 2:]
    poses = poses.reshape((-1, 4, 4))
    # poses = dict(zip(ids, poses))
    return ids, poses

def load_buffer(bag_path):
    tf_topics = ['/tf', '/tf_static']
    buffer = BufferCore(rospy.Duration(24 * 60 * 60))
    stamps = []

    try:
        with Bag(bag_path, 'r') as bag:
            # i = 0
            n = bag.get_message_count(topic_filters=tf_topics)
            for topic, msg, stamp in tqdm(bag.read_messages(topics=tf_topics),
                                          desc='%s: reading transforms' % bag_path.split('/')[-1],
                                          total=n):
                # i += 1
                # if i / n > 0.05:
                #     print('Only reading first 5% of transforms.')
                #     break
                if topic == '/tf':
                    for tf in msg.transforms:
                        buffer.set_transform(tf, 'bag')
                        stamps.append(tf.header.stamp.to_sec())
                elif topic == '/tf_static':
                    for tf in msg.transforms:
                        buffer.set_transform_static(tf, 'bag')
                        stamps.append(tf.header.stamp.to_sec())
    except ROSBagException as ex:
        print('Could not read %s: %s' % (bag_path, ex))

    stamps = sorted(stamps)
    return buffer, stamps


def localization_accuracy(bag_paths, fixed_frame='map', pose_frame_id='os_sensor'):
    data_path = '/home/ruslan/data/datasets/depth_correction/22-11-24-kn_e2_corridor/'
    # if bag_paths is None:
    bag_paths = os.listdir(os.path.join(data_path, 'bags/postprocessing/'))
    bag_paths = [os.path.join(data_path, 'bags/postprocessing/', b) for b in bag_paths]
    for bag_path in bag_paths:
        if bag_path[-4:] != '.bag':
            print('%s probably is not a bag file' % bag_path)
            continue
        if 'ScaledPolynomial' in bag_path:
            continue
        if not ('1376' in bag_path):
            continue
        assert os.path.exists(bag_path)
        poses = []
        assert 'seq1' in bag_path or 'seq2' in bag_path
        seq = 'seq1' if 'seq1' in bag_path else 'seq2'
        poses_path = os.path.join(data_path, 'sequences/%s/poses/poses.csv' % seq)
        stamps, gt_poses = read_poses(poses_path)

        buffer, _ = load_buffer(bag_path=bag_path)

        r_angles = []
        t_norms = []
        rel_angles = []
        rel_offsets = []
        for i, s in enumerate(stamps):
            stamp = str_to_sec(s)
            # Get cloud pose in fixed frame to check mutual cloud distance.
            try:
                tf = buffer.lookup_transform_core(fixed_frame, pose_frame_id, rospy.Time.from_seconds(stamp))
            except TransformException as ex:
                print('Could not find transform from %s to %s. Skipping. %s'
                      % (pose_frame_id, fixed_frame, ex))
                continue
            slam_pose = numpify(tf.transform)
            poses.append(slam_pose)

            # evaluate localization accuracy
            delta = delta_transform(slam_pose, gt_poses[i])
            r_angle = rotation_angle(delta)
            t_norm = translation_norm(delta)

            rel_angle = r_angle / len(gt_poses)
            rel_offset = t_norm / len(gt_poses)

            r_angles.append(r_angle)
            t_norms.append(t_norm)
            rel_angles.append(rel_angle)
            rel_offsets.append(rel_offset)

            # print('SLAM err. for pose %i / %i (%s): %.3f deg. (%.3g deg/m), %.3f m (%.3g %%).' %
            #       (i, len(gt_poses), str(stamps[i]),
            #        np.degrees(r_angle).item(), np.degrees(rel_angle).item(), t_norm, 100. * rel_offset))

        r_angle = np.mean(r_angles).item()
        t_norm = np.mean(t_norms).item()
        rel_angle = np.mean(rel_angles).item()
        rel_offset = np.mean(rel_offsets).item()

        print('-' * 30 + '\nBag file: %s' % bag_path)
        print('Average error: rot. %.6f deg. (%.3f deg/m), transl. %.6f m (%.3f %%).' %
              (np.degrees(r_angle).item(), np.degrees(rel_angle).item(), t_norm, 100. * rel_offset))

        # if len(poses) > 0:
        #     poses = np.asarray(poses)
        #     plt.figure()
        #     plt.plot(poses[:, 0, 3], poses[:, 1, 3], 'ro')
        #     plt.plot(gt_poses[:, 0, 3], gt_poses[:, 1, 3], 'gx')
        #     plt.axis('equal')
        #     plt.grid()
        #     plt.show()


def main():
    args = get_arg_parser().parse_args()

    kwargs = vars(args)
    for k in sorted(kwargs):
        print('%s: %s' % (k, kwargs[k]))

    localization_accuracy(**kwargs)


if __name__ == '__main__':
    main()
