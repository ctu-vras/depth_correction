#! /usr/bin/env python

import matplotlib.pyplot as plt
import numpy as np
import torch
from tqdm import tqdm
import open3d as o3d
from data.fee_corridor import Dataset, dataset_names
from depth_correction.depth_cloud import DepthCloud
from depth_correction.model import ScaledPolynomial
from depth_correction.preproc import filtered_cloud, local_feature_cloud
from depth_correction.config import Config, PoseCorrection
from depth_correction.loss import icp_loss, create_loss
from depth_correction.eval import create_corrected_poses, global_cloud
from depth_correction.preproc import establish_neighborhoods, compute_neighborhood_features
from depth_correction.config import Loss, NeighborhoodType


def filter_window_outliers(cloud: DepthCloud, cfg: Config, y_min=-2.5, y_max=2.5):
    """
    Filter outliers related to lidar beams going through windows

    :param y_max:
    :param y_min:
    :param cloud:
    :param cfg:
    :return:
    """
    phi = np.deg2rad(50.8)
    Rot = torch.tensor([[np.cos(phi), -np.sin(phi), 0],
                        [np.sin(phi), np.cos(phi), 0],
                        [0, 0, 1]]).to(cfg.device)
    pts = cloud.points if cloud.points is not None else cloud.to_points()
    pts = (Rot @ pts.T).T
    y = pts[:, 1]
    mask = torch.logical_and(y > y_min, y < y_max)

    return cloud[mask]

def points_to_cloud(points_struct, cfg):
    # construct depth cloud objects from points
    cloud = DepthCloud.from_structured_array(points_struct, dtype=cfg.numpy_float_type(), device=cfg.device)

    # apply grid and depth filters
    cloud = filtered_cloud(cloud, cfg)
    # filter outlier points which do not belong to the corridor
    cloud = filter_window_outliers(cloud, cfg)

    # compute cloud features necessary for optimization (like normals and incidence angles)
    cloud = local_feature_cloud(cloud=cloud, cfg=cfg)

    # cloud.visualize()
    return cloud


def main():
    cfg = Config()
    cfg.grid_res = 0.2
    cfg.min_depth = 1.0
    cfg.max_depth = 20.0
    cfg.nn_r = 0.4
    cfg.data_step = 1
    cfg.lr = 0.001
    # cfg.optimizer_kwargs['betas'] = (0.5, 0.9)
    # cfg.optimizer_kwargs['weight_decay'] = 0.1
    cfg.n_opt_iters = 100
    cfg.device = 'cpu'
    cfg.dataset_kwargs['static_poses'] = True
    cfg.pose_correction = PoseCorrection.pose
    # cfg.loss = Loss.min_eigval_loss
    cfg.loss = Loss.trace_loss
    cfg.nn_type = NeighborhoodType.ball

    # train_name = dataset_names[0]
    # train_name = np.random.choice(dataset_names)
    train_name = 'seq2_end_10'
    print('Training on %s sequence' % train_name)
    ds = Dataset(name=train_name,
                 poses_path='/home/ruslan/workspaces/depth_correction_ws/src/depth_correction/gen/'
                            'fee_corridor_d1-25_g0.20/fee_corridor/seq2/slam_poses_norlab_icp_mapper.csv',
                 **cfg.dataset_kwargs)

    train_clouds = []
    for id in ds.ids:
        points_struct = ds.local_cloud(id)
        train_clouds.append(points_to_cloud(points_struct, cfg))

    train_poses = np.stack([ds.poses[id] for id in ds.ids])
    train_poses = torch.as_tensor(train_poses, device=cfg.device, dtype=cfg.torch_float_type())
    train_pose_deltas = torch.zeros((len(train_poses), 6),
                                    dtype=cfg.torch_float_type(), requires_grad=True, device=cfg.device)

    train_ns = establish_neighborhoods(clouds=train_clouds, poses=train_poses, cfg=cfg)

    model = ScaledPolynomial(w=[0.0, 0.0], exponent=[2, 4], device=cfg.device)
    # model = ScaledPolynomial(w=[0.0], exponent=[6], device=cfg.device)

    loss_fn = create_loss(cfg)

    # optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)
    optimizer = torch.optim.Adam([{'params': train_pose_deltas, 'lr': cfg.lr},
                                  {'params': model.parameters(), 'lr': cfg.lr}], **cfg.optimizer_kwargs)
    # optimizer = torch.optim.Adam([{'params': train_pose_deltas, 'lr': cfg.lr}])

    # ground truth data (map and Leica tracker positions):
    gt_points = ds.global_cloud(resolution_cm=5)
    gt_cloud = DepthCloud.from_structured_array(gt_points, device='cuda')
    gt_cloud.update_points()
    gt_xyz = np.stack([ds.leica_xyz[id] for id in ds.ids])
    gt_xyz = torch.as_tensor(gt_xyz, dtype=cfg.torch_float_type(), device=cfg.device)

    # run optimization loop
    fig, axes = plt.subplots(2, 2, figsize=(14.0, 14.0), constrained_layout=True, squeeze=False)
    fig.suptitle('ICP optimization')
    iters = []
    losses_train = []
    map_losses = []
    pose_losses = []
    for it in tqdm(range(cfg.n_opt_iters)):
        # update poses
        train_poses_corr = create_corrected_poses(train_poses, train_pose_deltas, cfg)
        train_poses_corr = torch.stack(train_poses_corr)

        cloud = global_cloud(clouds=train_clouds, model=model, poses=train_poses_corr)
        feats = compute_neighborhood_features(cloud=cloud, model=None, neighborhoods=train_ns, cfg=cfg)

        # compute icp loss
        loss_train, _ = loss_fn(feats)
        losses_train.append(loss_train.item())

        # optimization step
        # with torch.autograd.detect_anomaly():
        optimizer.zero_grad()
        loss_train.backward()
        optimizer.step()

        # evaluation (metrics)
        with torch.no_grad():
            pose_loss = torch.linalg.norm(gt_xyz - train_poses_corr[:, :3, 3], dim=1).mean()
            pose_losses.append(pose_loss.item())

            cfg.loss_kwargs['icp_point_to_plane'] = False
            cfg.loss_kwargs['icp_inlier_ratio'] = 0.8
            cloud = cloud.to(gt_cloud.device())
            map_loss, _ = icp_loss([[cloud, gt_cloud]], **cfg.loss_kwargs)
            map_losses.append(map_loss.item())

        iters.append(it)

        # visualization
        if True and it % 1 == 0:
            # visualization of results
            plt.cla()
            ax = axes[0, 0]
            ax.grid(visible=True)
            ax.set_ylabel('ICP train loss')
            ax.set_xlabel('Iterations')
            ax.plot(iters[1:], losses_train[1:], color='k')
            # ax.plot(iters, losses_train, color='k')

            ax = axes[0, 1]
            model.plot(ax, color='k')
            ax.grid(visible=True)
            ax.legend()

            ax = axes[1, 0]
            ax.grid(visible=True)
            ax.set_ylabel('Pose L2 loss')
            ax.set_xlabel('Iterations')
            ax.plot(iters, pose_losses, color='b')

            ax = axes[1, 1]
            ax.grid(visible=True)
            ax.set_ylabel('Map accuracy ICP loss')
            ax.set_xlabel('Iterations')
            ax.plot(iters, map_losses, color='b')


            plt.pause(0.001)
            plt.draw()

        if False and it % 50 == 0:
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(cloud.to_points().detach().cpu())
            pcd.colors = o3d.utility.Vector3dVector(torch.zeros_like(cloud.to_points().detach().cpu()) +
                                                    torch.tensor([0, 1, 0]))

            gt_pcd = o3d.geometry.PointCloud()
            gt_pcd.points = o3d.utility.Vector3dVector(gt_cloud.to_points().detach().cpu())
            gt_pcd.colors = o3d.utility.Vector3dVector(torch.zeros_like(gt_cloud.to_points().detach().cpu()) +
                                                       torch.tensor([0, 0, 1]))

            o3d.visualization.draw_geometries([pcd, gt_pcd])

    plt.show()


if __name__ == "__main__":
    main()
