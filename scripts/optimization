#! /usr/bin/env python

import matplotlib.pyplot as plt
import numpy as np
import torch
from tqdm import tqdm
from data.depth_correction import Dataset, dataset_names
from depth_correction.depth_cloud import DepthCloud
from depth_correction.model import ScaledPolynomial, ScaledInvCos
from depth_correction.preproc import \
    (filtered_cloud, local_feature_cloud, filter_grid, establish_neighborhoods, compute_neighborhood_features)
from depth_correction.config import Config
from depth_correction.loss import icp_loss
from depth_correction.preproc import global_cloud
from depth_correction.loss import loss_by_name
from depth_correction.dataset import create_dataset
import open3d as o3d


def filter_window_outliers(cloud: DepthCloud, cfg: Config, y_min=-2.5, y_max=2.5):
    """
    Filter outliers related to lidar beams going through windows

    :param y_max:
    :param y_min:
    :param cloud:
    :param cfg:
    :return:
    """
    phi = np.deg2rad(50.8)
    Rot = torch.tensor([[np.cos(phi), -np.sin(phi), 0],
                        [np.sin(phi), np.cos(phi), 0],
                        [0, 0, 1]]).to(cfg.device)
    pts = cloud.points if cloud.points is not None else cloud.to_points()
    pts = (Rot @ pts.T).T
    y = pts[:, 1]
    mask = torch.logical_and(y > y_min, y < y_max)

    return cloud[mask]

def sample_to_cloud(data, cfg):
    points_struct, pose = data

    # construct depth cloud objects from points
    cloud = DepthCloud.from_structured_array(points_struct, dtype=cfg.numpy_float_type(), device=cfg.device)

    # apply grid and depth filters to clouds
    cloud = filtered_cloud(cloud, cfg)
    # filter outlier points which do not belong to the corridor
    cloud = filter_window_outliers(cloud, cfg)

    # transform point clouds to the same world coordinate frame
    cloud = cloud.transform(torch.as_tensor(pose))

    # compute cloud features necessary for optimization (like normals and incidence angles)
    cloud = local_feature_cloud(cloud=cloud, cfg=cfg)
    cloud = cloud[cloud.mask]

    # cloud.visualize()
    return cloud


def main():
    cfg = Config()
    cfg.grid_res = 0.2
    cfg.min_depth = 1.0
    cfg.max_depth = 25.0
    cfg.nn_r = 0.4
    cfg.data_step = 1
    cfg.device = 'cuda'
    cfg.loss = 'icp_loss'
    cfg.loss_kwargs['icp_inlier_ratio'] = 0.3
    cfg.loss_kwargs['icp_point_to_plane'] = True
    cfg.dataset_kwargs['static_poses'] = True

    fig, axes = plt.subplots(1, 3, figsize=(21.0, 7.0), constrained_layout=True, squeeze=False)
    fig.suptitle('ICP optimization')

    loss_fn = loss_by_name(cfg.loss)

    np.random.shuffle(dataset_names)
    train_names = dataset_names[:-2]
    val_names = dataset_names[-2:]
    print('Constructing training:\n{%s}'
          '\nand validation:\n{%s}'
          '\nclouds sets...' % (',\n'.join(train_names), ',\n'.join(val_names)))
    train_clouds = [[sample_to_cloud(s, cfg) for s in Dataset(name=name, **cfg.dataset_kwargs)] for name in train_names]
    val_clouds = [[sample_to_cloud(s, cfg) for s in Dataset(name=name, **cfg.dataset_kwargs)] for name in val_names]

    loss_train0 = loss_fn(train_clouds, **cfg.loss_kwargs)[0]
    print('Loss on training set without correction: %f' % loss_train0)
    loss_val0 = loss_fn(val_clouds, **cfg.loss_kwargs)[0]
    print('Loss on validation set without correction: %f\n' % loss_val0)

    model = ScaledPolynomial(w=[0.0, 0.0], exponent=[2, 4], device=cfg.device)
    # model = ScaledPolynomial(w=[0.0], exponent=[6], device=cfg.device)

    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)

    # run optimization loop
    iters = []
    losses_train, losses_val = [], []
    best_model = ScaledPolynomial()
    min_loss = np.inf

    for it in tqdm(range(cfg.n_opt_iters)):
        train_clouds_corr = [[model(c) for c in seq_clouds] for seq_clouds in train_clouds]
        for sc in train_clouds_corr:
            for c in sc:
                c.update_points()

        # with torch.autograd.detect_anomaly():
        loss_train, _ = loss_fn(clouds=train_clouds_corr, **cfg.loss_kwargs, verbose=True)
        losses_train.append(loss_train.item())

        optimizer.zero_grad()
        loss_train.backward()
        optimizer.step()

        with torch.no_grad():
            val_clouds_corr = [[model(c) for c in seq_clouds] for seq_clouds in val_clouds]
            for sc in val_clouds_corr:
                for c in sc:
                    c.update_points()
            loss_val, _ = loss_fn(val_clouds_corr, **cfg.loss_kwargs)
            losses_val.append(loss_val.item())

        iters.append(it)

        if loss_val < min_loss:
            print('Saving better model:', model)
            min_loss = loss_val
            torch.save(model.state_dict(), 'best_model.pth')

        if it % 5 == 0:
            # visualization of results
            plt.cla()
            ax = axes[0, 0]
            ax.grid(visible=True)
            ax.set_ylabel('ICP train loss')
            ax.set_xlabel('Iterations')
            ax.plot(iters, losses_train, color='k')

            ax = axes[0, 1]
            ax.grid(visible=True)
            ax.set_ylabel('ICP val loss')
            ax.set_xlabel('Iterations')
            ax.plot(iters, losses_val, color='b')

            ax = axes[0, 2]
            model.plot(ax, color='k')
            ax.grid(visible=True)
            ax.legend()

            plt.pause(0.001)
            plt.draw()

    """
    Evaluation: load best trained model and compute losses and metrics
    """
    best_model.load_state_dict(torch.load('best_model.pth'))
    best_model = best_model.to(cfg.device)
    print('Found best model weights:')
    print(best_model)
    ax = axes[0, 2]
    best_model.plot(ax, color='b', label='Saved %s' % str(best_model))
    ax.legend()
    plt.pause(0.1)
    plt.draw()

    train_clouds_corr = [[best_model(c) for c in seq_clouds] for seq_clouds in train_clouds]
    for sc in train_clouds_corr:
        for c in sc:
            c.update_points()
    print('Loss on training set after correction: %f (%f)' %
          (loss_fn(train_clouds_corr, **cfg.loss_kwargs, verbose=True)[0], loss_train0))

    val_clouds_corr = [[best_model(c) for c in seq_clouds] for seq_clouds in val_clouds]
    for sc in val_clouds_corr:
        for c in sc:
            c.update_points()
    print('Loss on validation set after correction: %f (%f)' %
          (loss_fn(val_clouds_corr, **cfg.loss_kwargs, verbose=True)[0], loss_val0))

    """
    evaluate mapping (reconstruction) accuracy:
    estimate mapping error wrt the ground truth map
    """
    for i in range(len(val_clouds)):
        # get ground truth cloud
        ds = Dataset(name=val_names[i], move_to_origin=False)
        gt_points_struct = ds.global_cloud(resolution_cm=5.0)
        gt_cloud = DepthCloud.from_structured_array(gt_points_struct, device=cfg.device)
        gt_cloud.update_points()

        # sequence cloud before depth correction
        cloud = DepthCloud.concatenate(val_clouds[i])
        # sequence cloud after depth correction
        cloud_corr = DepthCloud.concatenate(val_clouds_corr[i])

        with torch.no_grad():
            cloud = filter_grid(cloud, grid_res=cfg.grid_res)
            cloud_corr = filter_grid(cloud_corr, grid_res=cfg.grid_res)
            gt_cloud = filter_grid(gt_cloud, grid_res=cfg.grid_res)

            # we don't compute point to plane distance (point to point instead)
            # as we don't estimate normals for the depth clouds
            cfg.loss_kwargs['icp_point_to_plane'] = False
            cfg.loss_kwargs['icp_inlier_ratio'] = 1.0
            map_loss, _ = icp_loss([[cloud, gt_cloud]], **cfg.loss_kwargs, verbose=True)
            map_loss_corr, _ = icp_loss([[cloud_corr, gt_cloud]], **cfg.loss_kwargs, verbose=True)

        print('Reconstruction error (point to point) BEFORE correction: %f (for sequence %s)' %
              (map_loss.item(), val_names[i]))
        print('Reconstruction error (point to point) AFTER  correction: %f (for sequence %s)' %
              (map_loss_corr.item(), val_names[i]))

        cloud = DepthCloud.concatenate(val_clouds_corr[i])
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(cloud.to_points().detach().cpu())
        pcd.colors = o3d.utility.Vector3dVector(torch.zeros_like(cloud.to_points().detach().cpu()) +
                                                torch.tensor([0, 1, 0]))

        gt_pcd = o3d.geometry.PointCloud()
        gt_pcd.points = o3d.utility.Vector3dVector(gt_cloud.points.cpu())
        gt_pcd.colors = o3d.utility.Vector3dVector(torch.zeros_like(gt_cloud.points.cpu()) +
                                                   torch.tensor([1, 0, 0]))

        o3d.visualization.draw_geometries([pcd.voxel_down_sample(cfg.grid_res),
                                           gt_pcd.voxel_down_sample(cfg.grid_res)])


if __name__ == "__main__":
    main()
