#! /usr/bin/env python
from __future__ import absolute_import, division, print_function
from depth_correction.config import Config, Loss, Model, PoseCorrection
from depth_correction.dataset import (
    create_dataset,
    DepthBiasDataset,
    FilteredDataset,
    NoisyDepthDataset,
    NoisyPoseDataset,
)
from depth_correction.depth_cloud import DepthCloud
from depth_correction.model import load_model, model_by_name
from depth_correction.preproc import filtered_cloud, global_cloud, local_feature_cloud
from depth_correction.train import train, TrainCallbacks
from depth_correction.utils import delta_transform, rotation_angle, timing, translation_norm
from geometry_msgs.msg import Transform, TransformStamped
import matplotlib
matplotlib.rcParams['axes.formatter.useoffset'] = False
import matplotlib.pyplot as plt
import numpy as np
import os
from ros_numpy import msgify
import rospy
from sensor_msgs.msg import PointCloud2
from tf2_msgs.msg import TFMessage
import torch


class TrainingDemo(TrainCallbacks):

    def __init__(self):
        super().__init__()

        # Training history
        self.iterations = []
        self.train_losses = []
        self.l2_losses = []
        self.pose_losses = []
        self.pose_deltas = []
        self.pose_delta_grads = []
        self.weights = []
        self.exponents = []

        # Visualization
        self.fig, self.ax = None, None
        self.setup_visualization()
        self.corrected_cloud_pub = rospy.Publisher('corrected_cloud', PointCloud2, queue_size=2)

        self.cfg = Config()
        # self.cfg.train_names = ['ground_plane/10']
        # self.cfg.train_names = ['open_box/n_6_density_25.0']
        # self.cfg.data_step = 1

        # meshes
        # self.cfg.train_names = ['simple_cave_01.obj']
        # self.cfg.train_names = ['simple_tunnel_01.obj']
        # self.cfg.train_names = ['gazebo_cave_world.ply']
        # self.cfg.train_names = ['burning_building_rubble.ply']
        # self.cfg.train_names = ['newer_college.ply']

        # self.cfg.dataset_kwargs['n_poses'] = 5
        # self.cfg.dataset_kwargs['size'] = ([100., 140.], [-20., 20.], [-50., 50.])
        # self.cfg.dataset_kwargs['size'] = ([-20., 20.], [-20., 20.], [-20., 20.])
        # self.cfg.data_step = 1

        # OKAY
        # self.cfg.train_names = ['asl_laser/apartment']
        self.cfg.train_names = ['asl_laser/apartment', 'asl_laser/eth']
        # self.cfg.train_names = ['newer_college/01_short_experiment']
        # NOT OKAY (lr 1e-3, pose and depth noise, def eigval bounds)
        # heavy shortening with noise
        # self.cfg.train_names = ['asl_laser/gazebo_summer']
        # first shorten, than 0 for up to 100 iter., terminated
        # self.cfg.train_names = ['asl_laser/gazebo_winter']
        # shortening (+0.002 instead -0.01)
        # without eigenvalue filter got to -0.0039
        # self.cfg.train_names = ['asl_laser/plain']
        # stays around zero for 20 iter.
        # learns better with no depth and pose noise, stays halfway
        # self.cfg.train_names = ['asl_laser/stairs']
        # self.cfg.train_names = ['asl_laser/wood_summer']
        # self.cfg.train_names = ['asl_laser/wood_autumn']
        self.cfg.data_step = 4
        # self.cfg.data_step = 8

        self.cfg.dataset = self.cfg.train_names[0].split('/')[0]
        # self.cfg.val_names = self.cfg.train_names
        # self.cfg.val_names = ['asl_laser/stairs']

        # Depth and grid filters prevent computing L2 loss since the points don't match.
        # self.cfg.min_depth = 0.0
        # self.cfg.max_depth = float('inf')
        self.cfg.min_depth = 1.0
        self.cfg.max_depth = 15.0
        # self.cfg.max_depth = 10.0
        # self.cfg.grid_res = 0.0
        # self.cfg.grid_res = 0.1
        self.cfg.grid_res = 0.1
        self.cfg.nn_k = 0
        # self.cfg.nn_r = 0.2
        self.cfg.nn_r = 0.25
        # self.cfg.nn_r = 0.4
        self.cfg.shadow_angle_bounds = []
        # self.cfg.eigenvalue_bounds = []
        # self.cfg.eigenvalue_bounds = [[0, -float('inf'), (self.cfg.nn_r / 8)**2],
        #                               [1, (self.cfg.nn_r / 4)**2, float('inf')]]
        # self.cfg.dir_dispersion_bounds = []
        # self.cfg.vp_dispersion_bounds = []
        self.cfg.log_filters = True

        self.depth_noise = 0.0
        # self.depth_noise = 0.03
        self.pose_noise = 0.0
        # self.pose_noise = 0.005
        # self.pose_noise = 0.05
        self.pose_noise_mode = NoisyPoseDataset.Mode.common
        self.cfg.pose_correction = PoseCorrection.common
        # self.cfg.pose_correction = PoseCorrection.none

        self.cfg.model_class = Model.ScaledPolynomial
        # self.cfg.model_kwargs['w'] = [-0.002]
        self.cfg.model_kwargs['w'] = [0.0]
        self.cfg.model_kwargs['exponent'] = [6.0]
        # self.cfg.model_kwargs['w'] = [-0.005, -0.005]
        # self.cfg.model_kwargs['exponent'] = [2.0, 4.0]
        self.cfg.model_kwargs['learnable_exponents'] = False
        self.cfg.model_state_dict = None
        # del self.cfg.model_kwargs['w']
        # self.cfg.model_kwargs['w'] = [0.0]
        # No distortion.
        # self.cfg.model_class = 'BaseModel'
        # self.cfg.model_state_dict = None
        self.gt_model = model_by_name(self.cfg.model_class)(**self.cfg.model_kwargs)

        self.cfg.loss = Loss.min_eigval_loss
        # self.cfg.loss = Loss.trace_loss
        self.cfg.loss_offset = False
        self.cfg.loss_kwargs['sqrt'] = False
        self.cfg.loss_kwargs['normalization'] = True
        self.cfg.optimizer = 'Adam'
        self.cfg.optimizer_kwargs['betas'] = (0.5, 0.9)
        self.cfg.optimizer_kwargs['weight_decay'] = 0.1
        self.cfg.lr = 0.0002

        self.cfg.n_opt_iters = 1000

        self.cfg.from_rosparam()
        self.cfg.to_yaml(os.path.join(self.cfg.log_dir, 'config.yaml'))

        self.ds = None
        self.tfs = None
        self.gt_clouds = None
        self.gt_poses = None
        self.create_ground_truth()
        # self.train_callbacks = DemoTrainCallbacks(gt_clouds=self.gt_clouds)

        self.gt_cloud_pub = rospy.Publisher('ground_truth_cloud', PointCloud2, queue_size=2)
        self.initial_cloud_pub = rospy.Publisher('initial_cloud', PointCloud2, queue_size=2)

        self.tf_static_pub = rospy.Publisher('/tf_static', TFMessage, latch=True, queue_size=2)
        self.tf_static_pub.publish(TFMessage(self.tfs))

    def noisy_dataset(self, ds):
        ds = DepthBiasDataset(ds, self.gt_model, cfg=self.cfg)
        ds = NoisyDepthDataset(ds, noise=self.depth_noise)
        ds = NoisyPoseDataset(ds, noise=self.pose_noise, mode=self.pose_noise_mode)
        return ds

    def create_ground_truth(self):
        kwargs = {}
        if self.cfg.train_poses_path:
            kwargs['poses_path'] = self.cfg.train_poses_path[0]
        # self.ds = create_dataset(self.cfg.train_names[0], self.cfg, **kwargs)
        self.ds = [create_dataset(name, self.cfg, **kwargs) for name in self.cfg.train_names]
        clouds = []
        poses = []
        self.tfs = []
        # FIXME: Using ground truth from first cloud. Use all?
        for i, (cloud, pose) in enumerate(self.ds[0]):
            # cloud = local_feature_cloud(cloud, self.cfg)
            # Keep normals, avoid recomputing dependent fields.
            cloud = DepthCloud.from_structured_array(cloud, dtype=self.cfg.numpy_float_type(), device=self.cfg.device)
            clouds.append(cloud)
            tf = TransformStamped()
            tf.transform = msgify(Transform, pose)
            assert isinstance(tf, TransformStamped)
            tf.header.stamp = rospy.Time.now()
            tf.header.frame_id = 'map'
            tf.child_frame_id = 'vp_%i' % i
            self.tfs.append(tf)
            pose = torch.as_tensor(pose)
            poses.append(pose)
        cloud = global_cloud(clouds, None, poses)
        # print('Ground-truth cloud fields: %s' % cloud.dtype.names)
        self.gt_clouds = [cloud]
        self.gt_poses = [poses]
        # self.ds = create_dataset(self.cfg.train_names[0], self.cfg)
        self.ds = [self.noisy_dataset(ds) for ds in self.ds]

    def spin(self):
        train(self.cfg, callbacks=self, train_datasets=self.ds, val_datasets=self.ds)

    def iteration_started(self, iter):
        pass

    def compute_l2_loss(self, clouds):
        # assert len(clouds) == 1
        l2_loss = 0.0
        with torch.no_grad():
            # TODO: Handle multiple gt clouds (zip takes shortest).
            for gt_cloud, cloud in zip(self.gt_clouds, clouds):
                assert isinstance(gt_cloud, DepthCloud)
                assert isinstance(cloud, DepthCloud)
                if len(gt_cloud) != len(cloud):
                    print('Ground-truth: %i points, output: %i points.' % (len(gt_cloud), len(cloud)))
                    continue
                # cloud_l2_loss = torch.linalg.norm(gt_cloud.get_points() - cloud.to_points(), dim=1).mean()
                cloud_l2_loss = torch.linalg.norm(gt_cloud.to_points() - cloud.to_points(), dim=1).mean()
                l2_loss += cloud_l2_loss.detach().item()
            return l2_loss

    def compute_pose_loss(self, poses):
        # assert len(poses) == 1
        r_loss, t_loss, n = 0.0, 0.0, 0
        with torch.no_grad():
            # TODO: Handle multiple gt poses (zip takes shortest).
            for ds_gt_poses, ds_poses in zip(self.gt_poses, poses):
                for gt_pose, pose in zip(ds_gt_poses, ds_poses):
                    if isinstance(gt_pose, torch.Tensor):
                        gt_pose = gt_pose.detach().numpy()
                    assert isinstance(gt_pose, np.ndarray)
                    if isinstance(pose, torch.Tensor):
                        pose = pose.detach().numpy()
                    assert isinstance(pose, np.ndarray)
                    delta = delta_transform(pose, gt_pose)
                    r_loss += rotation_angle(delta)
                    t_loss += translation_norm(delta)
                    n += 1
        r_loss = r_loss / n
        t_loss = t_loss / n
        return r_loss, t_loss

    # @timing
    def train_loss(self, iter, model, clouds, pose_deltas, poses, masks, loss):
        # print('Mask: %.3f' % masks[0].float().mean() if masks and masks[0] is not None else float('nan'))
        # print('Cloud mask: %.3f' % clouds[0].mask.float().mean() if clouds[0].mask is not None else float('nan'))
        self.iterations.append(iter)
        self.l2_losses.append(self.compute_l2_loss(clouds))
        # self.poses.append(poses[0].detach().cpu().numpy().copy())
        # print(pose_deltas[0])
        # print(pose_deltas[0].grad)
        self.pose_deltas.append(pose_deltas[0].detach().cpu().numpy().flatten().copy())
        if pose_deltas[0].grad is not None:
            self.pose_delta_grads.append(pose_deltas[0].grad.detach().cpu().numpy().flatten().copy())
        else:
            self.pose_delta_grads.append(np.array(6 * [float('nan')]))
        self.pose_losses.append(self.compute_pose_loss(poses))
        self.weights.append(model.w.detach().cpu().numpy().flatten().tolist())
        self.exponents.append(model.exponent.detach().cpu().numpy().flatten().tolist())
        self.train_losses.append(loss.detach().cpu().item())
        if iter % 5 == 0:
            self.visualize(model, clouds, poses)
            self.publish_cloud(self.gt_cloud_pub, self.gt_clouds[0])
            self.publish_cloud(self.corrected_cloud_pub, clouds[0])

    def setup_visualization(self):
        # self.fig, self.ax = plt.subplots(3, 2, figsize=(8.0, 10.0), squeeze=False)
        self.fig, self.ax = plt.subplots(4, 2, figsize=(8.0, 10.0), constrained_layout=True, squeeze=False)
        self.pose_delta_grad_ax = self.ax[2, 0].twinx()

    # @timing
    def plot_cloud(self, ax, cloud, marker, dims=(0, 1), n=100, **kwargs):
        assert len(dims) == 2
        assert isinstance(cloud, DepthCloud)
        idx = np.unique(np.linspace(0, len(cloud) - 1, n, dtype=int)).tolist()
        with torch.no_grad():
            pts = cloud.to_points()
            x = pts[idx, dims[0]].detach().numpy()
            y = pts[idx, dims[1]].detach().numpy()
        ax.plot(x, y, marker, **kwargs)
        # ax.scatter(x, y, marker, **kwargs)

    def plot_poses(self, ax, poses, marker, dims=(0, 1), **kwargs):
        assert len(dims) == 2
        x = [p[dims[0], 3] for p in poses]
        y = [p[dims[1], 3] for p in poses]
        ax.plot(x, y, marker, **kwargs)

    # @timing
    def publish_cloud(self, pub, cloud):
        assert isinstance(pub, rospy.Publisher)
        assert isinstance(cloud, DepthCloud)
        with torch.no_grad():
            arr = cloud.to_structured_array()
            msg = msgify(PointCloud2, arr)
            assert isinstance(msg, PointCloud2)
            msg.header.stamp = rospy.Time.now()
            msg.header.frame_id = 'map'
        pub.publish(msg)

    @timing
    def visualize(self, model, clouds, poses=None):
        clouds = [cloud.detach() for cloud in clouds]
        if poses is not None:
            poses = [pose.detach() for pose in poses]

        ax = self.ax[0, 0]
        ax.cla()
        ax.plot(self.iterations, self.train_losses)
        ax.set_xlabel('Iteration')
        ax.set_ylabel('Training Loss')
        # ax.get_major_formatter().set_useOffset(False)
        ax.grid()
        # ax.legend()

        ax = self.ax[0, 1]
        ax.cla()
        ax.plot(self.iterations, self.l2_losses)
        ax.set_xlabel('Iteration')
        ax.set_ylabel('Point Loss')
        ax.grid()
        # ax.legend()

        if self.weights:
            ax = self.ax[1, 0]
            ax.cla()
            if self.gt_model:
                gt_weights = self.gt_model.w.detach().cpu().numpy().flatten().tolist()
                for i in range(len(gt_weights)):
                    ax.plot(self.iterations, len(self.iterations) * [gt_weights[i]], label='Ground-Truth w %i' % i)
            for i in range(len(self.weights[0])):
                ax.plot(self.iterations, [w[i] for w in self.weights], label='Model w %i' % i)
            ax.set_xlabel('Iteration')
            ax.set_ylabel('Value')
            ax.grid()
            ax.legend()

        if self.gt_model:
            ax = self.ax[1, 1]
            ax.cla()
            # self.gt_model.plot(ax, label='%s (Ground Truth)' % str(self.gt_model))
            # model.plot(ax, label='%s (Iteration %i)' % (str(model), self.iterations[-1]))
            self.gt_model.plot(ax)
            model.plot(ax)
            ax.grid()
            ax.legend()

        ax = self.ax[2, 0]
        ax.cla()
        labels = ['tx', 'ty', 'tz', 'rx', 'ry', 'rz']
        vars = [list(var) for var in zip(*self.pose_deltas)]
        for var, label in zip(vars, labels):
            ax.plot(self.iterations, var, label=label)
        ax.set_xlabel('Iteration')
        ax.set_ylabel('Pose Delta')
        ax.grid()
        ax.legend(loc='upper left')

        ax = self.pose_delta_grad_ax
        ax.cla()
        vars = [list(var) for var in zip(*self.pose_delta_grads)]
        for var, label in zip(vars, labels):
            ax.plot(self.iterations, var, '--', label=label + ' grad')
        ax.set_ylabel('Pose Delta Gradient')
        ax.grid()
        ax.legend(loc='lower left')

        ax = self.ax[2, 1]
        ax.cla()
        ax.plot(self.iterations, [r for r, _ in self.pose_losses], label='Rotation [rad]')
        ax.plot(self.iterations, [t for _, t in self.pose_losses], label='Translation [m]')
        ax.set_xlabel('Iteration')
        ax.set_ylabel('Pose Loss')
        ax.grid()
        ax.legend()

        if self.gt_clouds:
            ax = self.ax[3, 0]
            ax.cla()
            self.plot_cloud(ax, self.gt_clouds[0], 'bx', mfc='none', markersize=5, label='Ground Truth Cloud')
            self.plot_cloud(ax, clouds[0], 'ro', mfc='none', markersize=5, label='Corrected Cloud')
            if self.gt_poses:
                self.plot_poses(ax, self.gt_poses[0], 'bs', mfc='none', markersize=5, label='Ground-Truth Viewpoints')
            if poses:
                self.plot_poses(ax, poses[0], 'rs', mfc='none', markersize=5, label='Corrected Viewpoints')
            ax.set_xlabel('x [m]')
            ax.set_ylabel('y [m]')
            # ax.set_aspect('equal')
            ax.grid()
            ax.legend()

            ax = self.ax[3, 1]
            ax.cla()
            self.plot_cloud(ax, self.gt_clouds[0], 'bx', dims=(0, 2), mfc='none', markersize=5, label='Ground Truth')
            self.plot_cloud(ax, clouds[0], 'ro', dims=(0, 2), mfc='none', markersize=5, label='Corrected')
            ax.set_xlabel('x [m]')
            ax.set_ylabel('z [m]')
            # ax.set_aspect('equal')
            ax.grid()
            ax.legend()

        # self.fig.tight_layout()
        # plt.subplots_adjust(left=0.15, top=0.975, right=0.975, bottom=0.05, hspace=0.5, wspace=0.75)
        # plt.subplots_adjust(left=0.05, top=0.975, right=0.975, bottom=0.05, hspace=0.25, wspace=0.5)
        plt.pause(0.001)
        # plt.show()

        print(self.cfg.log_dir)
        path = os.path.join(self.cfg.log_dir, 'train_demo.png')
        self.fig.savefig(path, dpi=300)


def main():
    rospy.init_node('training_demo', log_level=rospy.DEBUG)
    node = TrainingDemo()
    node.spin()


if __name__ == '__main__':
    main()
